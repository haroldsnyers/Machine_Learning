{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict survival on the Titanic\n",
    "In this Lab, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset contains 891 observations of 12 variables:\n",
    "* **PassengerId**: Unique ID for each passenger\n",
    "* **Survived**: Survival (0 = No; 1 = Yes)\n",
    "* **Pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* **Name**: Name\n",
    "* **Sex**: Sex\n",
    "* **Age**: Age\n",
    "* **Sibsp**: Number of Siblings/Spouses Aboard\n",
    "* **Parch**: Number of Parents/Children Aboard\n",
    "* **Ticket**: Ticket Number\n",
    "* **Fare**: Passenger Fare\n",
    "* **Cabin**: Cabin\n",
    "* **Embarked** Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "survival rate = 0.3838383838383838\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"titanic.csv\" )\n",
    "titanic.drop('Cabin', axis=1, inplace=True) # Drop this column because it contains a lot of Nan values\n",
    "titanic[\"Age\"].fillna(titanic[\"Age\"].median(),inplace=True)\n",
    "titanic[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "print ('survival rate =', titanic.Survived.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name  Sex   Age  SibSp  Parch  \\\n0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n4                           Allen, Mr. William Henry    1  35.0      0      0   \n\n             Ticket     Fare  Embarked  \n0         A/5 21171   7.2500         2  \n1          PC 17599  71.2833         0  \n2  STON/O2. 3101282   7.9250         2  \n3            113803  53.1000         2  \n4            373450   8.0500         2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 361
    }
   ],
   "source": [
    "# Some of the columns don't have predictive power, so let's specify which ones are included for prediction\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", 'SibSp' ,'Parch', \"Fare\", \"Embarked\"]  \n",
    "# We need now to convert text columns in predictors to numerical ones\n",
    "for col in predictors: # Loop through all columns in predictors\n",
    "    if titanic[col].dtype == 'object':  # check if column's type is object (text)\n",
    "        titanic[col] = pd.Categorical(titanic[col]).codes  # convert text to numerical\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.8105939004815409\n",
      "cross validation accuracy = 0.7901490077087383\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Split the data into a training set and a testing set\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic[predictors], titanic['Survived'], test_size=0.3, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "print ('train accuracy =', clf.score(X_train, y_train))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with one single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.9887640449438202\n",
      "test accuracy = 0.7574626865671642\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import from: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# your code here\n",
    "clf_dt = DecisionTreeClassifier(random_state=1)\n",
    "## FIT \n",
    "clf_dt.fit(X_train, y_train)\n",
    "## SCORE \n",
    "train_score = clf_dt.score(X_train, y_train)\n",
    "test_score = clf_dt.score(X_test, y_test)\n",
    "# your code here\n",
    "print ('train accuracy =', train_score)\n",
    "print ('test accuracy =', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are obtained in the same way of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1\n",
      " 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 1]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "y_pred = clf_dt.predict(X_test)# your code here\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.25 0.75]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.5  0.5 ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.8  0.2 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.25 0.75]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.5  0.5 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.25 0.75]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.5  0.5 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.8  0.2 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.5  0.5 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.25 0.75]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.25 0.75]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.5  0.5 ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "y_prob = clf_dt.predict_proba(X_test)# your code here\n",
    "print (y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around with some of the decision tree's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.8812199036918138\n",
      "cross validation accuracy = 0.8137323847510467\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# check the sklearn documentation and change the following parameters: max_depth, min_samples_split, min_samples_leaf \n",
    "clf_dt = DecisionTreeClassifier(random_state=1, max_depth=5, min_samples_split=15)# your code here)\n",
    "# your code here\n",
    "clf_dt.fit(X_train, y_train)\n",
    "train_score = clf_dt.score(X_train, y_train)\n",
    "print ('train accuracy =', train_score)# your code here)\n",
    "\n",
    "# Cross validation\n",
    "scores_dt = cross_val_score(clf_dt, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)# your code here\n",
    "print('cross validation accuracy =', scores_dt.mean())# your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision tree\n",
    "Set the max_depth parameter in the previous classifier to 3 and leave all the other ones to default values.<br>\n",
    "Open the tree.dot file in a text editor, copy the piece of code and paste it  [ @ webgraphviz.com](http://webgraphviz.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{0: 'Pclass', 1: 'Sex', 2: 'Age', 3: 'SibSp', 4: 'Parch', 5: 'Fare', 6: 'Embarked'}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(clf_dt, out_file='tree.dot')\n",
    "# As a reminder, these are the predicting features in order\n",
    "print (dict(zip(range(len(predictors)),predictors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image should look like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Image(\"DT.png\")\n",
    "# import pydot\n",
    "# (graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# graph.write_png('test.png')\n",
    "# Image(\"test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the survival of a female, Pclass 1 or 2, above age 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "proba = [[0.0952381 0.9047619]]\n",
      "class = [1]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "passenger1=np.array([1, 0, 3, 0, 0, 0, 0]).reshape([1, -1])# your code here]).reshape(1, -1)\n",
    "print ('proba =', clf_dt.predict_proba(passenger1))# your code here)\n",
    "print ('class =', clf_dt.predict(passenger1))# your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the survival of a male, above age 11.5, Pclass 2 or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# passenger2=np.array([# your code here]).reshape(1, -1)\n",
    "# print ('proba =', # your code here)\n",
    "# print ('class =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this decision tree, you can get a sense the relative importance between features. let's see which are the most important ones using the attribute: **feature\\_importances_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Importance\nSex         0.535202\nPclass      0.165342\nAge         0.123519\nFare        0.060527\nSibSp       0.059734\nEmbarked    0.043938\nParch       0.011738",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Sex</th>\n      <td>0.535202</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>0.165342</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.123519</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>0.060527</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.059734</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>0.043938</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.011738</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 371
    }
   ],
   "source": [
    "feat_imp = pd.DataFrame(clf_dt.feature_importances_, predictors, columns=['Importance'])\n",
    "feat_imp.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, **Parch** and **Fare** are the least important ones because they were not used for splitting, while **Sex** is the most important one since it was used first for splitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "A   [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier from sklearn.ensemble import RandomForestClassifier) is an ensemble of [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.9743178170144462\n",
      "cross validation accuracy = 0.8137323847510467\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# import from: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "# your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=1)  # by default, 10 trees are used\n",
    "# your code here\n",
    "clf_rf.fit(X_train, y_train)\n",
    "print ('train accuracy =', clf_rf.score(X_train, y_train))# your code here)\n",
    "\n",
    "# Cross validation\n",
    "scores_rf = cross_val_score(clf_dt, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)# your code here\n",
    "print('cross validation accuracy =', scores_rf.mean())# your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, you can print the feature importance of all the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Importance\nAge         0.266266\nFare        0.257963\nSex         0.239376\nPclass      0.087316\nSibSp       0.061535\nParch       0.054428\nEmbarked    0.033116",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Age</th>\n      <td>0.266266</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>0.257963</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>0.239376</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>0.087316</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.061535</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.054428</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>0.033116</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 373
    }
   ],
   "source": [
    "# your code here\n",
    "feat_imp = pd.DataFrame(clf_rf.feature_importances_, predictors, columns=['Importance'])\n",
    "feat_imp.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, like decision trees have a lot of parameters to tune. Usually, performance does not change linearly with parameters. Let's take as an example, the accuracy as a function of number of trees (**n_estimators**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Number of Trees')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 374
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trees=range(50)\n",
    "accuracy=np.zeros(50)\n",
    "for idx in range(len(trees)):\n",
    "    clf_rf=RandomForestClassifier(random_state=1, n_estimators=idx + 1)\n",
    "    clf_rf.fit(X_train,y_train)\n",
    "    accuracy[idx]=clf_rf.score(X_test, y_test)  \n",
    "\n",
    "plt.plot(trees, accuracy)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Number of Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, try to tune manually the following parameters: **min_samples_leaf, min_samples_split, max_depth, n_estimators** in order to increase cross validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.8780096308186196\n",
      "cross validation accuracy = 0.8249494376702922\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=1, min_samples_split=13, max_depth=7, n_estimators=25)# your code here)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "print ('train accuracy =', clf_rf.score(X_train, y_train))\n",
    "\n",
    "# Cross validation\n",
    "scores_rf = cross_val_score(clf_rf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =', scores_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be a difficult job to do manually. In other way is to search automatically the best combination of different ranges for these parameters. This is done using **Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score='raise-deprecating',\n       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n            oob_score=False, random_state=1, verbose=0, warm_start=False),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'min_samples_leaf': [1, 2, 3, 4], 'min_samples_split': [2, 4, 6, 8], 'n_estimators': [10, 20, 30, 40]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring='accuracy', verbose=0)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 376
    }
   ],
   "source": [
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "# your code here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'min_samples_leaf':list(range(1,5)),'min_samples_split':list(range(2,10,2)),\n",
    "          'n_estimators':list(range(10,50,10))}\n",
    "clf_rf2=RandomForestClassifier(random_state=1)\n",
    "clf_gs=GridSearchCV(clf_rf2, params, scoring = 'accuracy',cv=5)\n",
    "clf_gs.fit(titanic[predictors], titanic[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.8327721661054994"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 377
    }
   ],
   "source": [
    "# your code here\n",
    "clf_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 30}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 378
    }
   ],
   "source": [
    "# your code here\n",
    "clf_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these best parameters and check whether they achieve really the above cv accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train accuracy = 0.8860353130016051\n",
      "cross validation accuracy = 0.8328209542068248\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_rf3 = RandomForestClassifier(random_state=1, min_samples_leaf= 4, min_samples_split= 2, n_estimators= 30)# your code here) \n",
    "clf_rf3.fit(X_train, y_train)\n",
    "print ('train accuracy =', clf_rf3.score(X_train, y_train))\n",
    "\n",
    "scores_rf3 = cross_val_score(clf_rf3, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =',scores_rf3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, grid search allows you to find the best model parameters to improve your accuracy. Now, we can see the most important features of this last classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Importance\nSex         0.387434\nFare        0.204499\nAge         0.147745\nPclass      0.130683\nSibSp       0.053662\nParch       0.040667\nEmbarked    0.035311",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Sex</th>\n      <td>0.387434</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>0.204499</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.147745</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>0.130683</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.053662</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.040667</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>0.035311</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 380
    }
   ],
   "source": [
    "feat_imp = pd.DataFrame(clf_rf3.feature_importances_, predictors, columns=['Importance'])\n",
    "feat_imp.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}